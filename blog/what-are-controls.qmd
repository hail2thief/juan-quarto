---
draft: true
title: "What do controls do?"
date: "2026-01-01"
author: "Juan Tellez"
format: html
toc: true
---



```{r}
#| label: setup
#| include: false

knitr::opts_chunk$set(
  fig.width = 8,
  fig.height = 10 * 0.618,
  fig.retina = 3,
  dev = "ragg_png",
  fig.align = "center",
  out.width = "90%",
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  echo = FALSE,
  cache.extra = 1234  # Change number to invalidate cache
)

options(
  digits = 4,
  width = 300,
  dplyr.summarise.inform = FALSE
)


## libraries
library(tidyverse)
library(kableExtra)

# Nice ggplot theme
theme_nice = function() {
  theme_minimal(base_size = 12) + 
    theme(
      panel.grid.minor = element_blank(),
      plot.title = element_text(face = "bold", size = rel(1.25)),
      plot.subtitle = element_text(face = "plain"),
      plot.caption = element_text(face = "plain"),
      axis.title = element_text(face = "bold", size = rel(0.8)),
      axis.title.x = element_text(hjust = 0),
      axis.title.y = element_text(hjust = 1),
      strip.text = element_text(
        face = "bold",
        size = rel(0.8), hjust = 0
      ),
      strip.background = element_rect(fill = "grey90", color = NA),
      legend.title = element_text(size = rel(0.8)),
      legend.text = element_text(size = rel(0.8)),
      legend.position = "bottom",
      legend.justification = "left",
      legend.title.position = "top",
      legend.margin = margin(l = 0, t = 0)
    )
}

theme_set(theme_nice())

# palette
pal <- MoMAColors::moma.colors("VanGogh")




# kbl wrapper
my_kbl = function(x, ...) {
  kbl(
    x,
    digits = 2,          # always round to 2 decimals
    booktabs = TRUE,     # cleaner LaTeX/HTML tables
    align = "c",         # default alignment
    ...
  ) |>
    kable_styling(
      full_width = FALSE,
      bootstrap_options = c("striped", "hover"),
      position = "center"
    )
}
```


## Introduction


In grad school, one of the more mysterious concepts I encountered was the use of *controls* in regression analysis. The problem was clear: we have a situation where we want to estimate the effect of $X$ on $Y$, but there is a third variable, $Z$, that affects both $X$ and $Y$. $Z$ will confound our estimates of $X$ on $Y$, so we need to "control for" $Z$ in our regression.


```{r}
library(ggdag)

dagify(
  Y ~ X + Z,
  X ~ Z,
  exposure = "X",
  outcome = "Y",
  coords = list(
    x = c(X = 1, Y = 2, Z = 1),
    y = c(X = 1, Y = 1, Z = 2)
  )
) |> 
  ggdag::ggdag_status() +
  theme_dag(legend.position = "none")
```

But what does it mean to "control" for Z? What are we trying to do, exactly?


Some textbooks discuss controlling in terms of comparisons. Here's Gelman in *Regression and other stories*:

> We interpret the regression slopes as comparisons of individuals that differ in one predictor while being at the same levels of the other predictors.

Or from *The Effect*:

> If two observations have the same values of the other variables in the model, but one has a value ofð‘‹  that is one unit higher, the observation with the X one unit higher will on average have að‘Œthat is B1 units higher


I love this intuition. We'd say that *comparing two people of identical Z*, we'd expect someone with an additional year of $X$ to have $\beta_1$ more in $Y$. 


But how is regression *doing this*? What about the regression makes this comparison possible? 


Here is one way of thinking about this that clarified regression *controls* for me and their limitations. 


## Example: ideology and campaign finance


Say we're looking at Adam Bonica's data on campaign finance, from my `{juanr}` package. Each row is a political candidate:


```{r}
library(juanr)

bonica |> 
  head() |> 
  my_kbl(caption = "Sample of Bonica's campaign finance data")
```


Say we wanted to estimate the effect of ideology (`dwnom1`) on the amount of money raised (`total_receipts`). `dwnom1` measures ideology using the DW-NOMINATE score, which theoretically ranges from -1 (left-wing) to 1 (right-wing). 


We estimate this simple model:

```{r}
library(estimatr)
library(modelsummary)
mod = lm_robust(total_receipts ~ dwnom1, data = bonica)

modelsummary(list("No controls" = mod), 
             gof_map = "nobs", stars = TRUE)
```


We see that more left-wing candidates tend to raise more money: going from a perfect moderate to a perfect left-winger results in a $258,416 increase in fundraising. Considering the median candidate raises about 15k, this is sizable. 


Many things might confound this relationship. One potential confound ($Z$) is political party: the parties systematically have different ideologies and might also have different fundraising capacities. So we control for party:


```{r}
mod2 = lm_robust(total_receipts ~ dwnom1 + party, data = bonica)

modelsummary(list("No controls" = mod,
                  "Control for party" = mod2), 
             gof_map = "nobs", stars = TRUE)
```

Now the story is completely different: controlling for party, we see that more left-wing candidates raise *less* money. Going from a perfect moderate to a perfect left-winger results in almost 1.5 million more in fundraising. 


Using the "comparisons" language from the textbooks, we can say that *comparing two candidates from the same party*, the more left-wing candidate raises less money.


But how do we get here?


## Stratification


One way to think about the "comparisons" interpretation of controls is as a kind of **stratification**: when we control for $Z$, what we would like to do is see if the relationship between $X$ and $Y$ "holds" *within* levels of $Z$.

To put it in the "defensive" terms in which researchers typically operate, if someone says that the relationship between $X$ and $Y$ is confounded by $Z$, we can respond: "Well, if we look at two people with the same $Z$, do we still see a relationship between $X$ and $Y$?" If yes, then we can say that the relationship between $X$ and $Y$ is not fully explained by $Z$.


In our case, this would look like estimating the relationship between ideology and fundraising *within* each of the three parties in the data (Democrats, Republicans, and Independents):


```{r, echo = TRUE}
bonica |> 
  group_by(party) |> 
  summarise(
    mod = list(lm_robust(total_receipts ~ dwnom1, data = cur_data()))
  ) |> 
  mutate(tidy_mod = map(mod, broom::tidy)) |> 
  unnest(tidy_mod) |> 
  filter(term == "dwnom1") |> 
  select(party, estimate, std.error, p.value) |> 
  my_kbl(caption = "Effect of ideology on fundraising, by party")
```

We see that within each party, the relationship between ideology and fundraising is different, big and positive for Democrats, big and negative for Republicans, and weakly positive for Independents. 


So how do we get from these three estimates to one overall estimate that *controls for party*, as in the model at the top of the page?


The answer is that regression is doing a kind of weighted average of these within-group estimates. But it's not a simple average â€” the weights depend on specific features of each group.


## The weighting formula


When we estimate `lm(Y ~ X + Z)` where $Z$ is categorical, the coefficient on $X$ is a weighted average of the within-group slopes:

$$
\hat{\beta}_{\text{pooled}} = \frac{\sum_{g=1}^{G} w_g \cdot \hat{\beta}_g}{\sum_{g=1}^{G} w_g}
$$

where $\hat{\beta}_g$ is the slope of $X$ on $Y$ estimated within group $g$, and the weight $w_g$ is:

$$
w_g = (n_g - 1) \cdot \text{Var}_g(X)
$$

That is, the weight for each group reflects two things:

1. **Group size**: groups with more observations contribute more squared deviations, so they get more weight. This makes sense â€” we have more information about the relationship in larger groups.
2. **Within-group variance of $X$**: groups where the treatment variable $X$ varies more get more weight. This also makes sense â€” if everyone in a group has the same value of $X$, we can't learn anything about the effect of $X$ from that group.

This is an important result. It tells us that when we "control for $Z$", we are not giving equal voice to every level of $Z$. We are letting the levels of $Z$ that have more data and more variation in $X$ drive the overall estimate.


## Checking this with the Bonica data


Let's verify this with our running example. First, we compute the within-party slopes, group sizes, and variances of ideology:


```{r, echo = TRUE}
# drop rows with missing ideology or receipts (same as lm does internally)
bonica_complete <- bonica |>
  filter(!is.na(dwnom1), !is.na(total_receipts))

# within-party estimates, sample sizes, and variance of X
strat <- bonica_complete |>
  group_by(party) |>
  summarise(
    beta_g = coef(lm(total_receipts ~ dwnom1))["dwnom1"],
    n_g = n(),
    var_g = var(dwnom1)
  ) |>
  mutate(
    weight = (n_g - 1) * var_g
  )

strat |>
  my_kbl(caption = "Within-party estimates and weights")
```

Now we can compute the weighted average and compare it to the OLS estimate:


```{r, echo = TRUE}
# weighted average of within-party slopes
beta_weighted <- with(strat, sum(weight * beta_g) / sum(weight))

# OLS with party control
beta_ols <- coef(lm(total_receipts ~ dwnom1 + party, data = bonica_complete))["dwnom1"]

tibble(
  `Weighted average` = beta_weighted,
  `OLS with controls` = beta_ols
) |>
  my_kbl(caption = "Stratified weighted average vs. OLS coefficient")
```


The two estimates are the same.^[There can be minor numerical differences due to floating point arithmetic, but they are substantively identical.] This confirms that "controlling for party" in OLS is equivalent to: (1) estimating the ideology-fundraising relationship separately within each party, and (2) taking a weighted average of those estimates, where groups with more observations and more ideological variation get more influence.


Look back at the weights in the table above. This tells us which parties are driving the overall estimate. If one party has far more candidates and more spread in ideology, its within-party slope will dominate the controlled estimate.


## What this tells us about controls


This decomposition clarifies a few things about what controls do and don't do:


1. **Controls are about within-group comparisons.** When we control for $Z$, we are comparing units that share the same value of $Z$. The regression coefficient is a summary of these within-group relationships.

2. **The summary is not a simple average.** Groups with more data and more variation in $X$ contribute more. This means the controlled estimate might be driven by a subset of the data that you didn't intend to emphasize.

3. **With categorical controls, the logic is transparent.** We can literally split the data, estimate within each group, and see how the pieces combine. This is a good exercise to build intuition.

4. **With continuous controls, we're trusting linearity.** When $Z$ is continuous, we can't literally stratify â€” there are too many unique values of $Z$. Instead, regression assumes the relationship between $Z$ and $Y$ is linear, and "controls for $Z$" by removing a linear function of $Z$ from both $X$ and $Y$.^[This is the Frisch-Waugh-Lovell theorem: the coefficient on $X$ in `lm(Y ~ X + Z)` is the same as the coefficient from regressing the residuals of $Y \sim Z$ on the residuals of $X \sim Z$.] This is a stronger assumption than the categorical case, where we make no assumptions about the shape of the $Z$-$Y$ relationship within each group.

If the true relationship between $Z$ and $Y$ is nonlinear, a linear control for $Z$ may not fully remove the confounding. This is one reason why researchers sometimes use flexible controls (polynomials, splines, or fixed effects for binned continuous variables) â€” they're trying to get closer to the stratification ideal.


